{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、人工神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1、神经元"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "神经网络由大量的神经元相互连接而成。每个神经元接受线性组合的输入后，最开始只是简单的线性加权，后来给每个神经元加上了非线性的激活函数，从而进行非线性变换后输出。每两个神经元之间的连接代表加权值，称之为权重(weight)。不同的权重和激活函数，则会导致神经网络不同的输出。\n",
    "\n",
    "例子：\n",
    "给定一个未知数，让神经网络识别是什么数字。此时的神经网络的输出由一组被输入图像的像素所激活的输入神经元所定义。在通过非线性激活函数进行非线性变换后，神经元被激活然后被传递到其他神经元。重复这一过程，直到最后一个输出神经元被激活。从而识别当前数字是什么字。\n",
    "\n",
    "神经网络的每个神经元如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img-blog.csdn.net/20160716131107406\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://img-blog.csdn.net/20160716131107406\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于wx + b的形式，其中\n",
    "##### x1、x2表示输入变量\n",
    "##### w1、w2为权重，几个输入则意味着有几个权重，即每个输入都被赋予一个权重\n",
    "##### b为偏置biss\n",
    "##### g(z)为激活函数\n",
    "##### a为输出"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "还有一个简单的例子：\n",
    "这周末北京有一草莓音乐节，那去不去呢？决定你是否去有二个因素，这二个因素可以对应二个输入，分别用x1、x2表示。此外，这二个因素对做决策的影响程度不一样，各自的影响程度用权重w1、w2表示。一般来说，音乐节的演唱嘉宾会非常影响你去不去，唱得好的前提下 即便没人陪同都可忍受，但如果唱得不好还不如你上台唱呢。所以，我们可以如下表示：\n",
    "\n",
    "x1 ：是否有喜欢的演唱嘉宾。 = 1 你喜欢这些嘉宾； = 0 你不喜欢这些嘉宾。嘉宾因素的权重 = 7\n",
    "x2 ：是否有人陪你同去。 = 1 有人陪你同去； = 0 没人陪你同去。是否有人陪同的权重= 3。\n",
    "    \n",
    "🆗，决策模型就建立起来了：g(z) = g(w1*x2 + w2*x2 +b)，g表示激活函数，b理解成为了达到目标而做调整的偏置项\n",
    "\n",
    "一开始为了简单，人们把激活函数定义成一个线性函数，即对于结果做一个线性变化，比如一个简单的线性激活函数是g(z) = z，输出都是输入的线性变换。后来实际应用中发现，线性激活函数太过局限，于是人们引入了非线性激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 、激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常见的非线性激活函数有sigmoid、tanh、relu等等，sigmoid、tanh比较常见于全连接层，后者relu常见于卷积层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 非线性激活函数sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表达式：如图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img-blog.csdn.net/20160703105637734\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://img-blog.csdn.net/20160703105637734\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表达式解释：z是一个线性组合，比如z可以等于：b + w1*x1 + w2*x2。通过代入很大的正数或很小的负数到g(z)函数中可知，其结果趋紧于0或1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，sigmoid函数g(z)的图形表示如下( 横轴表示定义域z，纵轴表示值域g(z))："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img-blog.csdn.net/20160703105432793\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://img-blog.csdn.net/20160703105432793\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是说，sigmoid函数的功能是相当于把一个实数压缩至0到1之间。当z是非常大的正数时，g(z)会趋近于1，而z是非常小的负数时，则g(z)会趋近于0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "压缩至0到1有何用处呢？用处是这样一来便可以把激活函数看作一种“分类的概率”，比如激活函数的输出为0.9的话便可以解释为90%的概率为正样本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img-blog.csdnimg.cn/20190218213452278.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ZfSlVMWV92,size_16,color_FFFFFF,t_70\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://img-blog.csdnimg.cn/20190218213452278.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ZfSlVMWV92,size_16,color_FFFFFF,t_70\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = b + * + *，其中b为偏置项 假定取-30，、都取为20\n",
    "\n",
    "##### 如果 = 0  = 0，则z = -30，g(z) = 1/( 1 + e^-z )趋近于0。此外，从上图sigmoid函数的图形上也可以看出，当z=-30的时候，g(z)的值趋近于0\n",
    "###### 如果 = 0  = 1，或 =1  = 0，则z = b + * + * = -30 + 20 = -10，同样，g(z)的值趋近于0\n",
    "##### 如果 = 1  = 1，则z = b + * + * = -30 + 20*1 + 20*1 = 10，此时，g(z)趋近于1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "换言之，只有和都取1的时候，g(z)→1，判定为正样本；或取0的时候，g(z)→0，判定为负样本，如此达到分类的目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3、神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将下图的这种单个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img-blog.csdn.net/20160703140734967\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://img-blog.csdn.net/20160703140734967\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "组织在一起，便形成了神经网络。下图便是一个三层神经网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://img-blog.csdn.net/20160703140745657\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://img-blog.csdn.net/20160703140745657\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最左边输入层，中间隐藏层，最右边输出层(可以有多个)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 输入层（Input layer），众多神经元（Neuron）接受大量非线形输入讯息。输入的讯息称为输入向量。\n",
    "##### 输出层（Output layer），讯息在神经元链接中传输、分析、权衡，形成输出结果。输出的讯息称为输出向量。\n",
    "##### 隐藏层（Hidden layer），简称“隐层”，是输入层和输出层之间众多神经元和链接组成的各个层面。如果有多个隐藏层，则意味着多个激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
