{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My First Model(摄氏度转华氏度).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myh233/gitTUT/blob/master/My_First_Model(%E6%91%84%E6%B0%8F%E5%BA%A6%E8%BD%AC%E5%8D%8E%E6%B0%8F%E5%BA%A6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Cmw9qHWnHPtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 导入TensorFlow and NumPy"
      ]
    },
    {
      "metadata": {
        "id": "1JeF3AEy-VuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR) #告诉TensorFlow只记录错误消息\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qh_jQQP6IIAl",
        "colab_type": "code",
        "outputId": "01818830-a2c7-4144-8e1c-b2e431694bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "celsius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype=float)\n",
        "fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype=float)\n",
        "\n",
        "for i,c in enumerate(celsius_q):\n",
        "  print(\"{} 摄氏度 = {} 华氏度\".format(c,fahrenheit_a[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-40.0 摄氏度 = -40.0 华氏度\n",
            "-10.0 摄氏度 = 14.0 华氏度\n",
            "0.0 摄氏度 = 32.0 华氏度\n",
            "8.0 摄氏度 = 46.0 华氏度\n",
            "15.0 摄氏度 = 59.0 华氏度\n",
            "22.0 摄氏度 = 72.0 华氏度\n",
            "38.0 摄氏度 = 100.0 华氏度\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5z9Qt1TzMI3e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some Machine Learning terminology（一些机器学习术语）\n",
        " - **Feature(特征)** — The input(s) to our model. In this case, a single value — the degrees in Celsius(摄氏度).\n",
        "\n",
        " - **Labels(标签)** — The output our model predicts. In this case, a single value — the degrees in Fahrenheit(华氏度).\n",
        " \n",
        " - **Example** — A pair of inputs/outputs used during training. In our case a pair of values from `celsius_q` and `fahrenheit_a` at a specific index, such as `(22,72)`"
      ]
    },
    {
      "metadata": {
        "id": "PpO38ceiOHB5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the model(创造模型)\n",
        "Next create the model. We will use simplest possible model we can, a Dense network(一个密集的网络). Since the problem is straightforward(简单的), this network will require only a single layer(单层), with a single neuron(单个神经元). \n",
        "\n",
        "layer:神经元的层\n",
        "\n",
        "### Build a layer(建一个层)\n",
        "\n",
        "We'll call the layer `layer1` and create it by instantiating `tf.keras.layers.Dense` with the following configuration:\n",
        "\n",
        "*   `input_shape=[1]` — This specifies that the input to this layer is a single value(这指定该层的输入为单个值). That is, the shape is a one-dimensional array with one member(也就是说，这个shape是一个一维数组，只有一个元素). Since this is the first (and only) layer, that input shape is the input shape of the entire model. The single value is a floating point number, representing degrees Celsius.\n",
        "\n",
        "*   `units=1` — This specifies the number of neurons in the layer. The number of neurons defines how many internal variables the layer has to try to learn how to solve the problem (more later). Since this is the final layer, it is also the size of the model's output — a single float value representing degrees Fahrenheit. (In a multi-layered network, the size and shape of the layer would need to match the `input_shape` of the next layer.)"
      ]
    },
    {
      "metadata": {
        "id": "EabP_gUKJ1Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer1 = tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "#layer1为layer即该层的名字，units指定了这个层级将有多少内部变量"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DiOGFNhLRiNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assemble layers into the model(将各层组装到模型中)\n",
        "Once layers are defined, they need to be assembled into a model. The Sequential model definition takes a list of layers as argument, specifying the calculation order from the input to the output.\n",
        "\n",
        "This model has just a single layer, l0.\n",
        "(一旦定义了层，就需要将它们组装到模型中。序列模型定义以一组层作为参数，指定从输入到输出的计算顺序。\n",
        "这个模型只有一个单层，layer1)"
      ]
    },
    {
      "metadata": {
        "id": "KXNmSi_DQzKA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([layer1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjnnwoaQSrJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note(另一种创造层以及组装到模型的方法)**\n",
        "\n",
        "You will often see the layers defined inside the model definition, rather than beforehand:\n",
        "\n",
        "```python\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "```"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N2O6P4xKVJyM"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile the model(编译模型), with loss and optimizer functions\n",
        "\n",
        "Before training, the model has to be compiled. When compiled for training, the model is given:\n",
        "\n",
        "- **Loss function(损失函数)** — A way of measuring how far off predictions are from the desired outcome. (The measured difference is called the \"loss\".)(一种衡量预测与预期结果之间距离的方法)\n",
        "在每次迭代过程中衡量模型好坏的函数称为“损失函数”，每次调整的目标是“最小化损失函数”。\n",
        "- **Optimizer function(优化器)** — A way of adjusting internal values in order to reduce the loss(一种调整内部值以减少损失的方法).\n",
        "\n",
        "- **TensorFlow**在训练中使用损失函数和优化器来寻找最佳模型"
      ]
    },
    {
      "metadata": {
        "id": "joOiTJDrS_rE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(0.1))#Adam优化器\n",
        "#mean_squared_error(均方误差)\n",
        "#Adam优化器，这里的0.1称为学习速率(0.1-0.001之间)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yvufuFVsV5zg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model(训练模型)\n",
        "Train the model by calling the `fit` method(通过调用model的fit方法). \n",
        "\n",
        "During training, the model takes in Celsius values, performs a calculation using the current internal variables (called \"weights\") and outputs values which are meant to be the Fahrenheit equivalent. Since the weights are initially set randomly, the output will not be close to the correct value. The difference between the actual output and the desired output is calculated using the loss function, and the optimizer function directs how the weights should be adjusted. \n",
        "\n",
        "This cycle of calculate, compare, adjust is controlled by the `fit` method. The first argument is the inputs(第一个参数是输入), the second argument is the desired outputs(第二个参数是期望的输出). The `epochs` argument specifies how many times this cycle should be run, and the `verbose` argument controls how much output the method produces.One epoch is a full iteration of the examples we have seen(一个周期是指对我们看到的样本进行一次完整的迭代，本例中一共有七个样本，一次迭代将训练7个样本).\n"
      ]
    },
    {
      "metadata": {
        "id": "g8Ziv6tBSU_I",
        "colab_type": "code",
        "outputId": "ed7fcfd4-3807-45f1-93c3-a9d4b26210b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "history1 = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)\n",
        "print(\"Finished training the model\")\n",
        "#epochs参数指定这个循环应该运行多少次，verbose参数控制方法产生多少输出\n",
        "#我们一共有7个摄氏度-华氏度映射样本，所以模型一共将训练500*7=3500个样本"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished training the model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mAs4OcCxZ66i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Display training statistics(显示训练的统计数据)\n",
        "The `fit` method returns a history object. We can use this object to plot how the loss of our model goes down after each training epoch. A high loss means that the Fahrenheit degrees the model predicts is far from the corresponding value in `fahrenheit_a`. \n",
        "\n",
        "We'll use [Matplotlib](https://matplotlib.org/) to visualize this (you could use another tool). As you can see, our model improves very quickly at first, and then has a steady, slow improvement until it is very near \"perfect\" towards the end.\n",
        "\n",
        "fit方法返回一个history对象。我们可以使用这个对象来绘制我们的模型在每个训练周期之后的损失是如何下降的。高损耗意味着模型预测的华氏温度远低于华氏温度的对应值。\n",
        "我们将使用Matplotlib将其可视化(您可以使用另一个工具)。正如您所看到的，我们的模型一开始改进得非常快，然后有一个稳定的、缓慢的改进，直到接近“完美”为止。"
      ]
    },
    {
      "metadata": {
        "id": "UqCRB68QYDRS",
        "colab_type": "code",
        "outputId": "9c4805b5-7597-44cc-8743-179a32201d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel(\"Loss Magnitude\")\n",
        "plt.plot(history1.history['loss'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff1642b1be0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "n0PgS26-avee",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use the model to predict values(用模型来预测一些值)"
      ]
    },
    {
      "metadata": {
        "id": "mM2mq0X6aaIt",
        "colab_type": "code",
        "outputId": "81312837-7f8d-4088-d0ac-e20259c8d2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.predict([100.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[211.74744]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xg9iIohfb2wN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The correct answer is $100 \\times 1.8 + 32 = 212$, so our model is doing really well.\n",
        "\n",
        "### To review(回顾)\n",
        "\n",
        "\n",
        "*   We created a model with a Dense laye(密集层)\n",
        "*   We trained it with 3500 examples (7 pairs, over 500 epochs).\n",
        "\n",
        "Our model tuned the variables (weights) in the Dense layer until it was able to return the correct Fahrenheit value for any Celsius value. (Remember, 100 Celsius was not part of our training data.)\n",
        "\n",
        "我们的模型调整了密集层中的变量(权重)，直到它能够返回任何摄氏度的正确华氏值。(记住，100摄氏度不是我们训练数据的一部分。)"
      ]
    },
    {
      "metadata": {
        "id": "vC6cQsOacuWJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Looking at the layer weights\n",
        "\n",
        "Finally, let's print the internal variables(内部变量) of the Dense layer. \n",
        "\n",
        "之前的公式是：华氏度=1.8*摄氏度 +32"
      ]
    },
    {
      "metadata": {
        "id": "qkBIs9EKcsmC",
        "colab_type": "code",
        "outputId": "1a9814d5-f57b-4d74-c4b1-c850029fe32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"These are the layer variables: {}\".format(layer1.get_weights()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These are the layer variables: [array([[1.7979496]], dtype=float32), array([31.952477], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bWqYUUo2d8RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### A little experiment(一个小尝试)\n",
        "\n",
        "Just for fun, what if we created more Dense layers with different units, which therefore also has more variables?(如果我们用不同的units创建更密集的层会怎样?)"
      ]
    },
    {
      "metadata": {
        "id": "pPp0B_4JdVIv",
        "colab_type": "code",
        "outputId": "0601a933-1304-4c06-ed45-e5dd8e61055a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "#建造层\n",
        "layer1 = tf.keras.layers.Dense(units=4, input_shape=[1])\n",
        "layer2 = tf.keras.layers.Dense(units=4)  \n",
        "layer3 = tf.keras.layers.Dense(units=1)  #units指定了这个层级将有多少内部变量\n",
        "#将各层组装到模型中\n",
        "model = tf.keras.Sequential([layer1, layer2, layer3])\n",
        "#编译模型\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\n",
        "#训练模型\n",
        "model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)\n",
        "print(\"Finished training the model\")\n",
        "#使用模型进行预测\n",
        "print(model.predict([100.0]))\n",
        "print(\"Model predicts that 100 degrees Celsius is: {} degrees Fahrenheit\".format(model.predict([100.0])))\n",
        "print(\"These are the layer1 variables: {}\".format(layer1.get_weights()))\n",
        "print(\"These are the layer2 variables: {}\".format(layer2.get_weights()))\n",
        "print(\"These are the layer3 variables: {}\".format(layer3.get_weights()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished training the model\n",
            "[[211.74744]]\n",
            "Model predicts that 100 degrees Celsius is: [[211.74744]] degrees Fahrenheit\n",
            "These are the layer1 variables: [array([[ 0.3063273 , -0.5380941 , -0.42691758,  0.06389692]],\n",
            "      dtype=float32), array([-1.2932868, -3.4025347, -3.4261405, -2.6540382], dtype=float32)]\n",
            "These are the layer2 variables: [array([[ 0.42099327,  0.1487053 ,  0.02881597, -0.94457555],\n",
            "       [ 0.631018  , -0.6140325 ,  0.81398344, -1.4333494 ],\n",
            "       [ 0.32621858, -0.57941675,  0.7481062 , -1.2644941 ],\n",
            "       [ 0.36339658, -1.1782414 ,  0.8338976 , -0.08310834]],\n",
            "      dtype=float32), array([-0.49771434,  3.6327891 , -3.6530952 ,  2.8846815 ], dtype=float32)]\n",
            "These are the layer3 variables: [array([[-0.11503559],\n",
            "       [ 0.93307686],\n",
            "       [-0.7620561 ],\n",
            "       [ 0.70753974]], dtype=float32), array([3.2762382], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "967bBL1Piqa_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 本节完整代码如下："
      ]
    },
    {
      "metadata": {
        "id": "TjBcuahne10_",
        "colab_type": "code",
        "outputId": "0cc5e797-e250-40c7-a8e4-66ea3e0391d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "import numpy as np\n",
        "\n",
        "celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)\n",
        "fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)\n",
        "\n",
        "l0 = tf.keras.layers.Dense(units=1, input_shape=[1]) \n",
        "model = tf.keras.Sequential([l0])\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\n",
        "history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)\n",
        "model.predict([100.0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[211.33835]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "eK9um4kckOAW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 小结"
      ]
    },
    {
      "metadata": {
        "id": "Us315aWkkXqD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "训练流程以前向传播开始，在此流程中，我们将输入数据提供给神经网络（请参见图 1）然后，模型将内部数学运算应用到输入和内部变量上，从而预测答案（在图 1 中，“模型预测出一个值”）。\n",
        "\n",
        "在我们的示例中，输入是摄氏度数，模型预测出相应的华氏度数。\n",
        "\n",
        "![替代文字](https://s3.cn-north-1.amazonaws.com.cn/u-img/efabce2c-75ab-427c-bd58-76e7c34b2121)\n",
        ">>>>>>>>>>>图1.前向传播\n"
      ]
    },
    {
      "metadata": {
        "id": "w87XgfhYlSYQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "预测出一个值后，模型将计算预测值与正确值之间的差值。这个差值称为损失，用于衡量模型执行映射任务的效果。我们使用损失函数计算损失，并且在调用 model.compile() 时通过损失参数指定损失函数。\n",
        "\n",
        "计算损失后，模型将调整所有层级的内部变量（权重和偏差），从而最小化该损失，使输出值更接近正确值（请参见图 2）\n",
        "\n",
        "![替代文字](https://s3.cn-north-1.amazonaws.com.cn/u-img/f8e4f660-1a6f-49e6-853c-491f5d1df8cd)\n",
        ">>>>>>>>>>>图2.反向传播\n",
        "\n",
        "这个优化流程称为梯度下降法。我们会通过一个具体算法计算每个内部变量的新值，并且在调用 model.compile(...) 时用优化器参数指定该算法。在此示例中，我们使用的是 Adam 优化器。"
      ]
    },
    {
      "metadata": {
        "id": "WI30yYbtl3I0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 基本属于的含义：\n",
        "- **特征**：模型的输入\n",
        "- **样本**：用于训练流程的输入/输出对\n",
        "- **标签**：模型的输出\n",
        "- **层级**：神经网络中相互连接的节点集合。\n",
        "- **模型**：神经网络的表示法\n",
        "- **密集全连接层 (FC)**：一个层级中的每个节点都与上个层级中的每个节点相连。\n",
        "- **权重和偏差**：模型的内部变量\n",
        "- **损失**：期望输出和真实输出之间的差值\n",
        "- **MSE**：均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕。\n",
        "- **梯度下降法**：每次小幅调整内部变量，从而逐渐降低损失函数的算法。\n",
        "- **优化器**：梯度下降法的一种具体实现方法。（有很多算法。在这门课程中，我们将仅使用“Adam”优化器，它是 ADAptive with Momentum 的简称，并且被视为最佳优化器。）\n",
        "- **学习速率**：梯度下降过程中的损失改进“步长”。\n",
        "- **批次**：在训练神经网络的过程中使用的一组样本。\n",
        "- **周期**：完全经过整个训练数据集一轮\n",
        "- **前向传播**：根据输入计算输出值\n",
        "- **反向传播**：根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层。"
      ]
    }
  ]
}